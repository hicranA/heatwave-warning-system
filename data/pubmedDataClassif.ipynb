{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read pubmed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "      <td>Not found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country      title    authors   abstract\n",
       "0  Papua New Guinea  Not found  Not found  Not found\n",
       "1  Papua New Guinea  Not found  Not found  Not found\n",
       "2         Singapore  Not found  Not found  Not found\n",
       "3  Papua New Guinea  Not found  Not found  Not found\n",
       "4         Singapore  Not found  Not found  Not found"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open('pubmed.pkl', 'rb'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dataset for training the model\n",
    "\n",
    "dataset = [\n",
    "    # Class 1: Indicates a country has a heatwave system\n",
    "    {\"text\": \"Australia, recognizing the increasing threat of heatwaves, has recently launched its National Heatwave Warning System. This system aims to provide timely alerts to residents and help them prepare for extreme temperatures.\", \"label\": 1},\n",
    "    {\"text\": \"In response to the devastating heatwaves of the past decade, the government of Spain has implemented a comprehensive Heatwave Plan. This initiative focuses on early detection and public awareness campaigns.\", \"label\": 1},\n",
    "    {\"text\": \"Canada's new Heat Alert and Response System (HARS) has been instrumental in reducing heat-related illnesses. The system provides guidelines for communities to prepare for and respond to extreme heat events.\", \"label\": 1},\n",
    "    {\"text\": \"The UK's Met Office, in collaboration with the National Health Service, has introduced a heatwave warning service. This service issues alerts when there's a high chance of an upcoming heatwave.\", \"label\": 1},\n",
    "\n",
    "    # Class 0: Does not indicate a country has a heatwave system or talks about unrelated topics\n",
    "    {\"text\": \"Heatwaves have been a recurring phenomenon in many parts of Africa. Communities have developed traditional methods to cope with extreme temperatures, such as building houses with specific materials.\", \"label\": 0},\n",
    "    {\"text\": \"The toy industry has seen a surge in sales during the summer months. Many attribute this trend to children staying indoors to escape the heat.\", \"label\": 0},\n",
    "    {\"text\": \"While many countries grapple with the challenges of heatwaves, there has been no official statement from Greenland regarding the implementation of a warning system.\", \"label\": 0},\n",
    "    {\"text\": \"The film industry often releases summer blockbusters during heatwaves, capitalizing on people seeking air-conditioned theaters.\", \"label\": 0},\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenized_dataset = tokenizer([item['text'] for item in dataset], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "labels = torch.tensor([item['label'] for item in dataset])\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(tokenized_dataset.input_ids, tokenized_dataset.attention_mask, labels)\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Model Initialization\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract'].fillna(\"Not found\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abstract(abstract_text):\n",
    "    if abstract_text == \"Not found\" or not abstract_text:\n",
    "        return \"No prediction\"\n",
    "    \n",
    "    # Ensure abstract_text is a string\n",
    "    abstract_text = str(abstract_text)\n",
    "    \n",
    "    # Tokenize the input abstract\n",
    "    tokenized_text = tokenizer(abstract_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    with torch.no_grad():\n",
    "        prediction = model(tokenized_text.input_ids, tokenized_text.attention_mask)\n",
    "    predicted_label = torch.argmax(prediction.logits, dim=1).item()\n",
    "    \n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "abstract = \"In recent years, many countries have recognized the dangers of heatwaves. Some states, understanding the severity of the situation, have introduced systems to warn residents about impending heatwaves. These systems aim to provide timely alerts to help citizens take necessary precautions.\"\n",
    "result = classify_abstract(abstract)\n",
    "print(\"Predicted Label:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_label'] = df['abstract'].apply(classify_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heatwaves in Europe and the USA have been shown to cause excess mortality among older persons. The summer of 2018 was unusually hot in south-eastern Norway. The purpose of this study was to investigate whether more older persons died that summer compared with the average for the previous ten summers.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['predicted_label']== 0].iloc[1]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_predict(abstract_text):\n",
    "    # Dataset with paragraphs (your training data)\n",
    "    dataset = [\n",
    "    # Class 1: Indicates a country has a heatwave system\n",
    "    {\"text\": \"Australia, recognizing the increasing threat of heatwaves, has recently launched its National Heatwave Warning System. This system aims to provide timely alerts to residents and help them prepare for extreme temperatures.\", \"label\": 1},\n",
    "    {\"text\": \"In response to the devastating heatwaves of the past decade, the government of Spain has implemented a comprehensive Heatwave Plan. This initiative focuses on early detection and public awareness campaigns.\", \"label\": 1},\n",
    "    {\"text\": \"Canada's new Heat Alert and Response System (HARS) has been instrumental in reducing heat-related illnesses. The system provides guidelines for communities to prepare for and respond to extreme heat events.\", \"label\": 1},\n",
    "    {\"text\": \"The UK's Met Office, in collaboration with the National Health Service, has introduced a heatwave warning service. This service issues alerts when there's a high chance of an upcoming heatwave.\", \"label\": 1},\n",
    "\n",
    "    # Class 0: Does not indicate a country has a heatwave system or talks about unrelated topics\n",
    "    {\"text\": \"Heatwaves have been a recurring phenomenon in many parts of Africa. Communities have developed traditional methods to cope with extreme temperatures, such as building houses with specific materials.\", \"label\": 0},\n",
    "    {\"text\": \"The toy industry has seen a surge in sales during the summer months. Many attribute this trend to children staying indoors to escape the heat.\", \"label\": 0},\n",
    "    {\"text\": \"While many countries grapple with the challenges of heatwaves, there has been no official statement from Greenland regarding the implementation of a warning system.\", \"label\": 0},\n",
    "    {\"text\": \"The film industry often releases summer blockbusters during heatwaves, capitalizing on people seeking air-conditioned theaters.\", \"label\": 0},\n",
    "    ]\n",
    "\n",
    "    # Tokenization\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenized_dataset = tokenizer([item['text'] for item in dataset], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    labels = torch.tensor([item['label'] for item in dataset])\n",
    "\n",
    "    # DataLoader\n",
    "    dataset = TensorDataset(tokenized_dataset.input_ids, tokenized_dataset.attention_mask, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    # Model Initialization\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Training Loop\n",
    "    num_epochs = 3\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Prediction\n",
    "    tokenized_text = tokenizer(abstract_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(tokenized_text.input_ids, tokenized_text.attention_mask)\n",
    "    predicted_label = torch.argmax(prediction.logits, dim=1).item()\n",
    "\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69744e047147443d89327948aed7e445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/hicranarnold/Documents/githubRepos/heatwaves/heatwave-warning-system/.env/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "abstract = \"In recent years, many countries have recognized the dangers of heatwaves. Some states, understanding the severity of the situation, have introduced systems to warn residents about impending heatwaves. These systems aim to provide timely alerts to help citizens take necessary precautions.\"\n",
    "result = train_and_predict(abstract)\n",
    "print(\"Predicted Label:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/hicranarnold/Documents/githubRepos/heatwaves/heatwave-warning-system/.env/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "abstract = \"i love this world\"\n",
    "result = train_and_predict(abstract)\n",
    "print(\"Predicted Label:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abstract(abstract):\n",
    "    if abstract == \"Not found\":\n",
    "        return -1  # or any default value you want\n",
    "    return train_and_predict(abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
